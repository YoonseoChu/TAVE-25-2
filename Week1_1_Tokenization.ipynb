{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **(파이토치 트랜스포머를 활용한) 자연어 처리와 컴퓨터비전 심층학습**\n",
        "## 5장 토큰화 (p230~ p263)"
      ],
      "metadata": {
        "id": "QtuqA8n3Aa8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [토크나이저 모델 학습]\n",
        "\n",
        "청와대 청원 데이터 사용"
      ],
      "metadata": {
        "id": "NQ0ioNLgAq5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece Korpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "6A-yli8KBB6i",
        "outputId": "6e91a945-44dc-4e1f-b437-65a555388b1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Collecting Korpora\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting dataclasses>=0.6 (from Korpora)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from Korpora) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.12/dist-packages (from Korpora) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from Korpora) (2.32.4)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from Korpora) (2.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20.0->Korpora) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20.0->Korpora) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20.0->Korpora) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20.0->Korpora) (2025.8.3)\n",
            "Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: dataclasses, Korpora\n",
            "Successfully installed Korpora-0.2.0 dataclasses-0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses"
                ]
              },
              "id": "e572eef737724fb49ddfe3d1a44e31c8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9DGMCNC-a2U",
        "outputId": "fa77eb5d-0520-4cb3-af7f-d203c584a2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : Hyunjoong Kim lovit@github\n",
            "    Repository : https://github.com/lovit/petitions_archive\n",
            "    References :\n",
            "\n",
            "    청와대 국민청원 게시판의 데이터를 월별로 수집한 것입니다.\n",
            "    청원은 게시판에 글을 올린 뒤, 한달 간 청원이 진행됩니다.\n",
            "    수집되는 데이터는 청원종료가 된 이후의 데이터이며, 청원 내 댓글은 수집되지 않습니다.\n",
            "    단 청원의 동의 개수는 수집됩니다.\n",
            "    자세한 내용은 위의 repository를 참고하세요.\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[korean_petitions] download petitions_2017-08: 1.84MB [00:00, 15.1MB/s]                           \n",
            "[korean_petitions] download petitions_2017-09: 20.4MB [00:00, 59.0MB/s]                            \n",
            "[korean_petitions] download petitions_2017-10: 12.0MB [00:00, 55.4MB/s]                            \n",
            "[korean_petitions] download petitions_2017-11: 28.4MB [00:00, 73.2MB/s]                            \n",
            "[korean_petitions] download petitions_2017-12: 29.0MB [00:00, 103MB/s]                             \n",
            "[korean_petitions] download petitions_2018-01: 43.9MB [00:00, 151MB/s]                            \n",
            "[korean_petitions] download petitions_2018-02: 33.8MB [00:00, 147MB/s]                            \n",
            "[korean_petitions] download petitions_2018-03: 34.3MB [00:00, 137MB/s]                            \n",
            "[korean_petitions] download petitions_2018-04: 35.5MB [00:00, 142MB/s]                            \n",
            "[korean_petitions] download petitions_2018-05: 37.5MB [00:00, 147MB/s]                            \n",
            "[korean_petitions] download petitions_2018-06: 37.8MB [00:00, 140MB/s]                            \n",
            "[korean_petitions] download petitions_2018-07: 40.5MB [00:00, 126MB/s]                            \n",
            "[korean_petitions] download petitions_2018-08: 39.8MB [00:00, 159MB/s]                            \n",
            "[korean_petitions] download petitions_2018-09: 36.1MB [00:00, 109MB/s]                            \n",
            "[korean_petitions] download petitions_2018-10: 38.1MB [00:00, 112MB/s]                            \n",
            "[korean_petitions] download petitions_2018-11: 37.7MB [00:00, 140MB/s]                            \n",
            "[korean_petitions] download petitions_2018-12: 33.0MB [00:00, 119MB/s]                             \n",
            "[korean_petitions] download petitions_2019-01: 34.8MB [00:00, 136MB/s]                            \n",
            "[korean_petitions] download petitions_2019-02: 30.8MB [00:00, 114MB/s]                            \n",
            "[korean_petitions] download petitions_2019-03: 34.9MB [00:00, 142MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "청원 시작일 : 2017-08-25\n",
            "청원 종료일 : 2017-09-24\n",
            "청원 동의 수 : 88\n",
            "청원 범주 : 육아/교육\n",
            "청원 제목 : 학교는 인력센터, 취업센터가 아닙니다. 정말 간곡히 부탁드립니다.\n",
            "청원 본문 : 안녕하세요. 현재 사대, 교대 등 교원양성학교들의 예비\n"
          ]
        }
      ],
      "source": [
        "# 청와대 청원 데이터 다운로드\n",
        "\n",
        "from Korpora import Korpora\n",
        "\n",
        "corpus = Korpora.load(\"korean_petitions\")\n",
        "dataset = corpus.train\n",
        "petition = dataset[0]\n",
        "\n",
        "print(\"청원 시작일 :\", petition.begin)\n",
        "print(\"청원 종료일 :\", petition.end)\n",
        "print(\"청원 동의 수 :\", petition.num_agree)\n",
        "print(\"청원 범주 :\", petition.category)\n",
        "print(\"청원 제목 :\", petition.title)\n",
        "print(\"청원 본문 :\", petition.text[:30])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터세트 생성\n",
        "from Korpora import Korpora\n",
        "\n",
        "corpus = Korpora.load(\"korean_petitions\")\n",
        "petitions = corpus.get_all_texts()\n",
        "\n",
        "with open(\"/content/corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for petition in petitions:\n",
        "        f.write(petition + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfa59pNpBXEt",
        "outputId": "4bc856e6-91ae-49d7-db7d-52501ed6734c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : Hyunjoong Kim lovit@github\n",
            "    Repository : https://github.com/lovit/petitions_archive\n",
            "    References :\n",
            "\n",
            "    청와대 국민청원 게시판의 데이터를 월별로 수집한 것입니다.\n",
            "    청원은 게시판에 글을 올린 뒤, 한달 간 청원이 진행됩니다.\n",
            "    수집되는 데이터는 청원종료가 된 이후의 데이터이며, 청원 내 댓글은 수집되지 않습니다.\n",
            "    단 청원의 동의 개수는 수집됩니다.\n",
            "    자세한 내용은 위의 repository를 참고하세요.\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-08\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-09\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-10\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-11\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2017-12\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-01\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-02\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-03\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-04\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-05\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-06\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-07\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-08\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-09\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-10\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-11\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2018-12\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-01\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-02\n",
            "[Korpora] Corpus `korean_petitions` is already installed at /root/Korpora/korean_petitions/petitions_2019-03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 모델 학습\n",
        "from sentencepiece import SentencePieceTrainer\n",
        "\n",
        "SentencePieceTrainer.Train(\n",
        "    \"--input=/content/corpus.txt \"\n",
        "    \"--model_prefix=/content/petition_bpe \"\n",
        "    \"--vocab_size=8000 \"\n",
        "    \"--model_type=bpe\"\n",
        ")"
      ],
      "metadata": {
        "id": "iUg2VhqQA5cw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 바이트 페어 인코딩 토큰화\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "tokenizer = SentencePieceProcessor()\n",
        "tokenizer.load(\"/content/petition_bpe.model\")  # <- 경로 수정\n",
        "\n",
        "sentence = \"안녕하세요, 토크나이저가 잘 학습되었군요!\"\n",
        "sentences = [\"이렇게 입력값을 리스트로 받아서\", \"쉽게 토크나이저를 사용할 수 있답니다\"]\n",
        "\n",
        "tokenized_sentence = tokenizer.encode_as_pieces(sentence)\n",
        "tokenized_sentences = [tokenizer.encode_as_pieces(s) for s in sentences]\n",
        "print(\"단일 문장 토큰화 :\", tokenized_sentence)\n",
        "print(\"여러 문장 토큰화 :\", tokenized_sentences)\n",
        "\n",
        "encoded_sentence = tokenizer.encode_as_ids(sentence)\n",
        "encoded_sentences = [tokenizer.encode_as_ids(s) for s in sentences]\n",
        "print(\"단일 문장 정수 인코딩 :\", encoded_sentence)\n",
        "print(\"여러 문장 정수 인코딩 :\", encoded_sentences)\n",
        "\n",
        "decode_ids = [tokenizer.decode_ids(ids) for ids in encoded_sentences]\n",
        "decode_pieces = [tokenizer.decode_pieces(tokenizer.encode_as_pieces(s)) for s in sentences]\n",
        "print(\"정수 인코딩에서 문장 변환 :\", decode_ids)\n",
        "print(\"하위 단어 토큰에서 문장 변환 :\", decode_pieces)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmnvdPVeCNi-",
        "outputId": "4f7dc7bf-994f-49a7-c2c8-417ae0aa14a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단일 문장 토큰화 : ['▁안녕하세요', ',', '▁토', '크', '나', '이', '저', '가', '▁잘', '▁학', '습', '되었', '군요', '!']\n",
            "여러 문장 토큰화 : [['▁이렇게', '▁입', '력', '값을', '▁리', '스트', '로', '▁받아서'], ['▁쉽게', '▁토', '크', '나', '이', '저', '를', '▁사용할', '▁수', '▁있', '답니다']]\n",
            "단일 문장 정수 인코딩 : [667, 6553, 994, 6880, 6544, 6513, 6590, 6523, 161, 110, 6554, 872, 787, 6648]\n",
            "여러 문장 정수 인코딩 : [[372, 182, 6677, 4433, 1772, 1613, 6527, 4162], [1681, 994, 6880, 6544, 6513, 6590, 6536, 5852, 19, 5, 2639]]\n",
            "정수 인코딩에서 문장 변환 : ['이렇게 입력값을 리스트로 받아서', '쉽게 토크나이저를 사용할 수 있답니다']\n",
            "하위 단어 토큰에서 문장 변환 : ['이렇게 입력값을 리스트로 받아서', '쉽게 토크나이저를 사용할 수 있답니다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어휘 사전 불러오기\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "tokenizer = SentencePieceProcessor()\n",
        "tokenizer.load(\"/content/petition_bpe.model\")\n",
        "\n",
        "vocab = {idx: tokenizer.id_to_piece(idx) for idx in range(tokenizer.get_piece_size())}\n",
        "print(list(vocab.items())[:5])\n",
        "print(\"vocab size :\", len(vocab))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEcEUy7YCT02",
        "outputId": "b3a7d0c1-95fb-4582-b12c-139f78b698e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, '니다'), (4, '▁이')]\n",
            "vocab size : 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [워드피스 토크나이저 학습]"
      ],
      "metadata": {
        "id": "M3J_efusBwPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 워드피스 토크나이저 학습\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers.normalizers import Sequence, NFD, Lowercase\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "import os\n",
        "\n",
        "# 저장 폴더 생성\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "\n",
        "# 토크나이저 정의\n",
        "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
        "tokenizer.normalizer = Sequence([NFD(), Lowercase()])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "# WordPiece 트레이너 정의\n",
        "trainer = WordPieceTrainer(vocab_size=8000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
        "\n",
        "# 학습\n",
        "tokenizer.train(files=[\"/content/corpus.txt\"], trainer=trainer)\n",
        "\n",
        "# 저장\n",
        "tokenizer.save(\"/content/models/petition_wordpiece.json\")\n"
      ],
      "metadata": {
        "id": "eD7j8zj3Es28"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 워드피스 토큰화\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.decoders import WordPiece as WordPieceDecoder\n",
        "\n",
        "# 토크나이저 로드\n",
        "tokenizer = Tokenizer.from_file(\"/content/models/petition_wordpiece.json\")\n",
        "tokenizer.decoder = WordPieceDecoder()\n",
        "\n",
        "# 테스트 문장\n",
        "sentence = \"안녕하세요, 토크나이저가 잘 학습되었군요!\"\n",
        "sentences = [\"이렇게 입력값을 리스트로 받아서\", \"쉽게 토크나이저를 사용할 수 있답니다\"]\n",
        "\n",
        "# 단일 문장 인코딩\n",
        "encoded_sentence = tokenizer.encode(sentence)\n",
        "# 여러 문장 인코딩\n",
        "encoded_sentences = tokenizer.encode_batch(sentences)\n",
        "\n",
        "# 출력\n",
        "print(\"인코더 형식 :\", type(encoded_sentence))\n",
        "print(\"단일 문장 토큰화 :\", encoded_sentence.tokens)\n",
        "print(\"여러 문장 토큰화 :\", [enc.tokens for enc in encoded_sentences])\n",
        "print(\"단일 문장 정수 인코딩 :\", encoded_sentence.ids)\n",
        "print(\"여러 문장 정수 인코딩 :\", [enc.ids for enc in encoded_sentences])\n",
        "print(\"정수 인코딩에서 문장 변환 :\", tokenizer.decode(encoded_sentence.ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxelczJPE4YF",
        "outputId": "ca28e80c-4a90-4cc5-fb21-1210b938ae1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더 형식 : <class 'tokenizers.Encoding'>\n",
            "단일 문장 토큰화 : ['안', '##ᄂ', '##ᅧᆼ', '##하', '##세요', ',', 'ᄐ', '##ᅩ', '##ᄏ', '##ᅳ', '##나', '##이', '##저', '##가', '잘', '학', '##스', '##ᆸ', '##되', '##었', '##군', '##요', '!']\n",
            "여러 문장 토큰화 : [['이러', '##ᇂ게', '입', '##력', '##가', '##ᆹ', '##을', 'ᄅ', '##ᅵ', '##스', '##트', '##로', '받', '##아', '##서'], ['ᄉ', '##ᅱ', '##ᆸ', '##게', 'ᄐ', '##ᅩ', '##ᄏ', '##ᅳ', '##나', '##이', '##저', '##를', '사', '##용', '##할', '수', '있', '##다', '##ᆸ니다']]\n",
            "단일 문장 정수 인코딩 : [7625, 4229, 7508, 7487, 7723, 16, 313, 4224, 4281, 4230, 7538, 7480, 7541, 7493, 7847, 7779, 7517, 4251, 7562, 7734, 7963, 7520, 5]\n",
            "여러 문장 정수 인코딩 : [[7910, 7755, 7876, 7693, 7493, 4285, 7490, 302, 4226, 7517, 7758, 7500, 7706, 7547, 7505], [306, 4255, 4251, 7523, 313, 4224, 4281, 4230, 7538, 7480, 7541, 7515, 7533, 7613, 7658, 7567, 7531, 7483, 7494]]\n",
            "정수 인코딩에서 문장 변환 : 안녕하세요, 토크나이저가 잘 학습되었군요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rSvVeiINFIDW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}